.. include:: ../substitutions.rst

**************
Postprocessing
**************

.. _postprocess-tldr:

TL;DR
=====

The ``postprocess.py`` command-line tool can be used to analyze the results generated by ``match_template.py``.

.. code-block:: bash

    postprocess.py --help

.. tab-set::

    .. tab-item:: Orientations

        Executing the following code will generate a tab-separated file named `output.tsv` with eight columns. The z, y and x column correspond to the translation, the euler_z, euler_y and euler_x column to the rotation used to obtain the column score. The detail column provides some additional information based on the process with which the peaks were generated.

        The 1,000 identified peaks with higest score that are separated by at least 20 voxel and no less than 30 voxel distanced from the boundaries of the target will be written to disk when executing the following from within the shell:

        .. code-block:: bash

            postprocess.py \
                --input_file output.pickle \
                --output_prefix output \
                --output_format orientations \
                --min_distance 30 \
                --min_boundary_distance 20\
                --number_of_peaks 1000

        .. note::

            |project| uses the zyx convention, like the CCP4/MRC format. In `IMOD <https://bio3d.colorado.edu/imod/>`_ terms, a file read by :py:meth:`tme.density.Density.from_file` with data shape 500, 928, 960, will contain 960 columns, 928 rows and 500 sections. Similarly, the reported Euler angles are in intrinsic zyx convention (see :py:meth:`tme.matching_utils.euler_to_rotationmatrix` for reference).

    .. tab-item:: Alignments

        Executing the following code will align the template to the target used in ``match_template.py`` based on high-scoring orientations. These high-scoring orientations are written to disk, either as atomic structure or density depending on which was used as input for ``match_template.py``. The generated files follow the naming pattern {output_prefix}.{index}.{extension}. In the following example output_prefix would be output. Index 0 corresponds to the orientation with highest score, index 1 to the second largest and so on. Extension corresponds to the file extension of the template used in ``match_template.py``.

        The following will write no more than ten top scoring alignments
        to disk.

        .. code-block:: bash

            postprocess.py \
                --input_file output.pickle \
                --output_prefix output \
                --output_format alignment \
                --number_of_peaks 10

    .. tab-item:: Extraction

        Executing the following code will extract regions from the target with the dimension of the template used in ``match_template.py``. The output can be used for averaging, i.e. subtomograms, or alignment. The generated files follow the naming pattern {output_prefix}.{index}.mrc. In the following example output_prefix would be output. Index 0 corresponds to the orientation with highest score, index 1 to the second largest and so on.

        The following will write no more than 500 top scoring peaks separated by a distance of 20 voxel that have been identified using :py:class:`tme.analyzer.PeakCallerMaximumFilter` to disk.

        .. code-block:: bash

            postprocess.py \
                --input_file output.pickle \
                --output_prefix output \
                --output_format extraction \
                --min_distance 20 \
                --number_of_peaks 500 \
                --peak_caller PeakCallerMaximumFilter

    .. tab-item:: Relion

        This option will generate a `STAR <https://en.wikipedia.org/wiki/Self-defining_Text_Archive_and_Retrieval>`_ file and extract subtomograms which can be directly used input for reconstruction, refinement and downstream classification with `RELION <https://github.com/3dem/relion>`_. In terms of peak calling and subtomogram extraction, this option performs identical to the output_format ``extraction``. The output STAR file consists of an optics group block which contains informations about the imaging conditions, pixel size, and another data group with tab separated columns containing x, y, z coordinates (in voxels), a file path to the generated cropped subtomogram file, the Euler angles, namely rotation, tilt and psi.

        The output is compatible with RELION 4.0 and was tested with relion_reconstruct, and relion_refine_mpi.

        .. code-block:: bash

            postprocess.py \
                --input_file output.pickle \
                --output_prefix output \
                --output_format relion \
                --min_distance 20 \
                --number_of_peaks 1000 \
                -—wedge_mask mask.mrc

        .. note::

            Without a wedge mask or a fully fledged CTF, the averages computed by `RELION <https://github.com/3dem/relion>`_ might be overly distorted due to preferential alignment of subtomograms on the missing wedge. Wedge mask can be generated with pyTME (see :py:meth:`tme.preprocessor.Preprocessor.wedge_mask` and :py:meth:`tme.preprocessor.Preprocessor.continuous_wedge_mask`) or the Napari GUI (see :ref:`preprocessing section <filter-application>`).

            ``postprocess.py`` automatically pads the extracted subtomograms to an even number of voxels in each dimension to avoid potential RELION crashes.


You can find an overview of available peak calling methods :ref:`here <analyzer-label>`.

Aim
===

The aim of postprocessing is to determine regions of high similarity between template and target from the template matching output. This procedure is referred to hereafter as peak calling. Each peak corresponds to a unique occurence of the template in the target, which here is fully characterized by a translation vector, three Euler angles, a score and an additional data column.


Background
==========

Generally, high scores indicate regions of high similarity, and most scoring functions are limited to the interval [0, 1], with 1 being a perfect match (see :doc:`exhaustive template matching <../reference/matching_exhaustive>` for details on your specific scoring method).

``match_template.py`` performs an search of all rotational and translation degrees of freedom of the input. For a three-dimensional input this corresponds to a six-dimensional search. Due to memory contraints, this problem is simplified by only storing the maximum score for each translation of the template as well as the rotation used to obtain it. This results in two arrays with the same shape as the template.

To better understand this, lets recall an example from the :ref:`Preprocessing section <preprocess-filtering>`:

.. plot::

    import copy
    import numpy as np
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    from skimage.feature import match_template

    from tme import Density

    target = Density.from_file("../_static/examples/preprocessing_target.png").data
    template = Density.from_file("../_static/examples/preprocessing_template.png").data

    result = match_template(target, template, pad_input=True)
    ij = np.unravel_index(np.argmax(result), result.shape)
    x, y = ij[::-1]

    fig, ax = plt.subplots(nrows=1, ncols=1)
    ax.imshow(result)
    ax.set_title('Template Matching Score', color='#0a7d91')

    square_size = max(template.shape)
    rect = patches.Rectangle((x - square_size / 2, y - square_size / 2), square_size, square_size, edgecolor='red', facecolor='none')
    ax.add_patch(rect)

    plt.tight_layout()
    plt.show()

The score peak is highlighted within the red rectangle, and for this example is located at 111, 240. Therefore, the maximum similariy is obtained when translating the template so that is center of mass is at position 111, 240 within the target. This convention used in |project| to represent in scores and candidates is analogous to other tools and figuratively explained in a `skimage tutorial <https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_template.html>`_

The identity matrix is the corresponding rotation matrix for this peak. Different approaches are used to express rotations and translations. |project| centeres rotations around the center of mass and applies translations subsequently by default. match_template.py follows this default behaviour.

The following sections explain the output of ``match_template.py`` and outline the peak calling procedure used by ``postprocess.py``.


Template Matching Output
========================

The output of ``match_template.py`` is a `pickle <https://docs.python.org/3/library/pickle.html>`_ file that contains the output of the analyzer used on the scores, which by default is :py:class:`tme.analyzer.MaxScoreOverRotations`. The `pickle <https://docs.python.org/3/library/pickle.html>`_ file can be read using :py:meth:`tme.matching_utils.load_pickle` and contains five objects:

- **Scores Array**: A numpy array with scores mapped to translations.
- **Translation Offset**: A translation offset informing about shifts in coordinate sytems.
- **Rotations Array**: A numpy array detailing rotations connected to the scores from specific translations.
- **Rotation-Euler Dictionary**: A mapping of rotations to their corresponding Euler angles.
- **Metadata**: Coordinate system information relevant to subsequent analysis as well as all parameters that were used to enable reproducibility.


For those familiar with other tools, the output aligns with what's seen in `STOPGAP <https://github.com/williamnwan/STOPGAP>`_, `PyTom <https://github.com/FridoF/PyTom>`_ and `Situs colores <https://situs.biomachina.org/fguide.html#colores>`_.


However, when you use the `-p` flag with ``match_template.py``, the output structure differs. The flag triggers direct peak calling, altering the output to include:

- **Translations**: A numpy array containing translations with shape `number_peaks x dimensions`.
- **Rotations**: A numpy array containing rotations with shape `number_peaks x dimensions x dimensions`.
- **Scores**: The scoring values for each peak, defined by its translation and rotation.
- **Details**: Additional information regarding each peak.
- **Metadata**: Coordinate system information relevant to subsequent analysis as well as all parameters that were used to enable reproducibility.


Peak Calling
============

Regardless of the ``output_format``, ``postprocess.py`` will determine orientations where the template is most similar to the target. In the following we will have a look on what ``postprocess.py`` is doing under the hood.

Schematically, we will use the `pickle <https://docs.python.org/3/library/pickle.html>`_ file generated by ``match_template.py``, together with :py:class:`tme.analyzer.PeakCallerScipy` (see :ref:`analyzer-label` for further options) to identify a maximum of 1000 local maxima that are separated by a distance of 5 voxel. Typically it is reasonable to set ``min_distance`` and ``min_boundary_distance`` to the size of the smallest dimension of the template.

.. code-block:: python

    import pickle
    import numpy as np
    from tme.analyzer import PeakCallerScipy
    from tme.matching_utils import load_pickle

    # Loading ``match_template.py`` output.
    data = load_pickle("output.pickle")

    scores, offset, rotations, rotation_mapping, *_ = data

    # Calling peaks on score array
    peak_caller = PeakCallerScipy(
        number_of_peaks = 1000,
        min_distance = 5
    )
    peak_caller(scores, rotation_matrix = np.eye(3))
    candidates = tuple(peak_caller)

    # Writing orientations to disk
    header = "\t".join(["z", "y", "x", "euler_z", "euler_y", "euler_x", "score", "detail"])
    with open("output.tsv", mode = "w", encoding = "utf-8") as ofile:
        _ = ofile.write(f"{header}\n")
        for translation, _, score, detail in zip(*candidates):
            angles = rotation_mapping[rotations[tuple(translation)]]
            translation_string = "\t".join([str(x) for x in translation])
            angle_string = "\t".join([str(x) for x in angles])
            _ = ofile.write(f"{translation_string}\t{angle_string}\t{score}\n")

.. note::

    The determined candidates heavily depend on the used analyzer. For more details on available analzyers please refer to :ref:`analyzer-label`.

In summary, peak calling determines a local maximum in the computed `scores` array, looks up the corresponding rotation in the `rotations` array, converts the rotation index to Euler angles using `rotation_mapping`. The generated ``output.tsv`` file is equivalent to running ``postprocess.py`` with ``output_format`` orientations.


Usage Examples
==============

The following outlines how to use the output of ``postprocessing.py``'s ``output_format`` orientations for the previous section's :ref:`Usage Examples <match-template-usage-examples>`. We assume the generated orientations file is named ``output.tsv``.

.. tab-set::

    .. tab-item:: Particle Picking

        The most commonly used approach towards assessing picked particles is through manual filtering. This procedure is supported by the napari GUI shipped wiith |project|. Like in previous tutorials, using the GUI requires following the installation procedure outlined in the :ref:`gui-installation`. For an introduction how to operate the GUI see the :ref:`preprocessing section <filter-application>`.

        To showcase the GUI, we are going to utilze particle picks generated on the tomogram TS_037 [1]_. Launch the GUI application, drag and drop the tomogram into the viewer and subseqeuently used the `Import Point Cloud` button to select and import the output.tsv generated with ``postprocess.py`` in ``output_format`` orientations. The colors of the particles correspond to their respective score relativ to other elements of the same point cloud. The particles are colored according to the `Turbo` colorscale, with low scoring particles being colored in blue, and high scoring particles colored in red.

        .. figure:: ../_static/examples/napari_pointcloud_widget_intro.png
            :width: 100 %
            :align: center

        Using the controls outlined in blue, we can remove particles from the set by using the delete key. If you would like to change the color, size, or shape of the particles, you can select everything by clicking on the particle layer followed by Shift + A. Pressing Shift + A again clears the selection.

        Once you have removed particles that were deemed unreliable by manual inspection, you can export the remaining points using the `Export Point Cloud button`. This will generate an orientations tsv file anaologous to ``output_format`` orientations in ``postprocess.py``. You can even use this subsetted list for further analysis. Assuming the file generated by napari is called ``filtered_orientations.tsv`` you can utilize the ``orientations`` parameter of ``postprocess.py`` like so:

        .. code-block:: bash

            postprocess.py \
                --input_file output.pickle \
                --output_prefix output \
                --output_format extraction \
                --orientations filtered_orientations.tsv

        Executing the code above will extract all subtomograms from the filtered orientations file.


    .. tab-item:: Fit Atomic Structure

        Note, the code example below is equivalent to using ``postprocess.py`` with ``output_format`` alignment and serves an illustrative purpose.

        For this case, its common to inspect the positioning of the initial structure after translation and rotation in the electron density. The following transforms the initial structure and writes the top ten highest scoring orientations to disk.

        .. code-block:: python

            import pickle

            import numpy as np

            from tme import Density, Structure
            from tme.matching_utils import euler_to_rotationmatrix, load_pickle

            # Load and extract orientations
            orientations = []
            with open("output.tsv", mode = "r", encoding = "utf-8") as infile:
                data = infile.read().split("\n")

            # Remove header
            _ = data.pop(0)

            # Get coordinate system information
            target_origin, _, sampling_rate, meta = load_pickle("output.pickle").pop()

            # Convert string to floating point
            for orientation in data:
                orientation = orientation.split("\t")
                if len(orientation) == 1:
                    continue
                orientations.append([float(x) for x in orientation])

            # Load template and compute center of mass
            initial_structure = Structure.from_file("5UZ4.pdb")
            center_of_mass = initial_structure.center_of_mass()[::-1]

            # Generate candidates and write to disk
            n_candidates = min(10, len(orientations))
            for i in range(n_candidates):
                orientation = orientations[i]
                translation, rotation = orientation[0:3], orientation[3:6]
                translation = np.subtract(
                    np.multiply(translation, sampling_rate),
                    center_of_mass,
                )
                translation = np.add(translation, target_origin)
                rotation_matrix = euler_to_rotationmatrix(rotation)
                transformed_structure = initial_structure.rigid_transform(
                    translation = translation[::-1],
                    rotation_matrix = rotation_matrix[::-1, ::-1]
                )
                transformed_structure.to_file(f"{i}.pdb")

        .. note::

            Thoe operation outlined above is equivalent to using ``postprocess.py`` with ``output_format`` alignment.


    .. tab-item:: Alignment of Densities

        Note, the code example below is equivalent to using ``postprocess.py`` with ``output_format`` alignment and serves an illustrative purpose.

        The following transforms the initial density and writes the top ten highest scoring orientations to disk.

        .. code-block:: python

            import pickle

            import numpy as np

            from tme import Density
            from tme.matching_utils import euler_to_rotationmatrix, load_pickle

            # Load and extract orientations
            orientations = []
            with open("output.tsv", mode = "r", encoding = "utf-8") as infile:
                data = infile.read().split("\n")

            # Remove header
            _ = data.pop(0)

            # Get coordinate system information
            target_origin, _, sampling_rate, meta = load_pickle("output.pickle").pop()

            # Convert string to floating point
            for orientation in data:
                orientation = orientation.split("\t")
                if len(orientation) == 1:
                    continue
                orientations.append([float(x) for x in orientation])

            # Load template and compute center of mass
            initial_density = Density.from_file("emd_8621_transformed.mrc")
            initial_density, _ = initial_density.centered(0)
            center_of_mass = initial_density.center_of_mass(initial_density.data)

            n_candidates = min(10, len(orientations))
            for i in range(n_candidates):
                orientation = orientations[i]
                translation, rotation = orientation[0:3], orientation[3:6]
                translation = np.subtract(translation, center_of_mass)
                rotation_matrix = euler_to_rotationmatrix(rotation)
                transformed_density = initial_density.rigid_transform(
                    rotation_matrix = rotation_matrix
                )
                new_origin = np.add(target_origin / sampling_rate, translation)
                transformed_density.origin = np.multiply(new_origin, sampling_rate)
                transformed_density.to_file(f"{i}.mrc")


Troubleshooting
===============

The most insightful piece of information for troubleshooting are the computed scores, and their corresponding orientations. Assuming ``match_template.py`` generated a file ``output.pickle``, you can write the template matching scores and their corresponding rotations to disk within python as follows:

.. code-block:: python

    from tme import Density
    from tme.matching_utils import load_pickle

    # Loading ``match_template.py`` output.
    data = load_pickle("output.pickle")

    scores, offset, rotations, rotation_mapping, *_ = data

    Density(scores).to_file("scores.mrc")
    Density(rotations).to_file("rotations.mrc")

Executing the code above will generated two CCP4/MRC files ``scores.mrc`` and ``rotations.mrc``, that you can open in the napari GUI shipped with |project| or a macromolecular viewer of your choice. For reference, you can have a look at the :ref:`preprocessing section <preprocess-filtering>` to assess whether your results are reminiscent of examples there.

If no examples match your particular case, please feel free to open an issue in the |project| `repository <https://github.com/KosinskiLab/pyTME.git>`_.


Integrations with other Software
================================

The output of pyTME can be readily integrated with the refinement, classification and averaging procedures of existing software. The following subsections outline such integrations.


RELION
------

RELION (for REgularised LIkelihood OptimisatioN) uses a Bayesian approach for refinement of 3D reconstructions and the classification of particles. In simple terms, RELION is used to process cryo-electron microscopy data to create high-resolution three-dimensional structures of biological molecules [2]_.

The input required by RELION can be readily generated using ``postprocess.py`` with ``output_format`` relion. For further information refer to the :ref:`Postprocessing TL;DR Relion section <postprocess-tldr>`.

.. code-block:: bash

    postprocess.py \
        --input_file output.pickle \
        --output_prefix output \
        --output_format relion \
        --min_distance 20 \
        --number_of_peaks 1000 \
        -—wegde_mask mask.mrc

Using the generated STAR file, extracted subtomgrams and optimal agnles, an initial averaged reference structure can be generated with RELION from within a shell as follows:

.. code-block:: bash

    relion_reconstruct \
        --3d_rot \
        --i ${INPUT_STAR_FILE} \
        --o rec.mrc

The output ``rec.mrc`` is an average of all subtomograms using the provided angles as-is. If these angles aren’t precise there output average willl like approximate a spherical structure with little features.

This ``rec.mrc`` together with the STAR file can be used as input for a relion refinement job. Note this job should be run on the cluster ideally with GPU access. Global and local optimisation can be used. Note that the output directory needs to be created by the user prior to running RELION which will otherwise crash. Global optimisation should be used if the angles are likely of still low quality:

.. code-block:: bash

    mpirun -n 3 `which relion_refine_mpi` \
        --o ${OUTPUT_DIR} \
        --ctf \
        --auto_refine \
        --split_random_halves \
        --i ${INPUT_STAR_FILE} \
        --ref rec.mrc \
        --firstiter_cc \
        --ini_high 60 \
        --dont_combine_weights_via_disc \
        --pool 3 \
        --pad 2 \
        --particle_diameter 250 \
        --flatten_solvent \
        --zero_mask \
        --oversampling 1 \
        --healpix_order 2 \
        --auto_local_healpix_order 4 \
        --offset_range 5 \
        --offset_step 2 \
        --sym C1 \
        --low_resol_join_halves 40 \
        --norm \
        --scale  \
        --j 7 \
        --gpu

Local refinement can be used to run further improve the angles locally if these are of good quality:

.. code-block:: bash

    mpirun -n 3 `which relion_refine_mpi` \
        --o ${OUTPUT_DIR} \
        --auto_refine \
        --split_random_halves \
        --i ${INPUT_STAR_FILE} \
        --ref rec.mrc \
        --firstiter_cc \
        --ini_high 60 \
        --dont_combine_weights_via_disc \
        --pool 3 \
        --pad 2 \
        --particle_diameter 230 \
        --flatten_solvent \
        --zero_mask \
        --oversampling 1 \
        --healpix_order 4 \
        --auto_local_healpix_order 4 \
        --offset_range 5 \
        --offset_step 2 \
        --sym C1 \
        --low_resol_join_halves 40 \
        --norm \
        --scale  \
        --j 7 \
        --gpu

A SLURM batch submission script can be found :doc:`here <code_examples/postprocessing_relion_sbatch>`. The specific queues, run times and other specs need to be adapted to each specific cluster and tech specs.

The output refined average in the {OUTPUT_DIR} can be inspected using third party software such as Chimera. RELION generates an angldist bild file which which can be loaded in Chimera to display the angle distribution after optimization:

.. figure:: ../_static/examples/relion_ribosome_example.png
    :width: 100 %
    :align: center

The Global refinement might not converge to a good structure if the angles are not identified from template matching sufficiently well. For demonstration purposes the initial template can be used as reference to ensure the refinement settles into a reasonable minimum during averaging. For better results, further optimization, classification, a much higher particle count and precise CTF correction are needed. We refer users to other workflows such as the Warp-M-Relion pipeline for further improving their resolution.


IMOD
----

In the case of particle picking its usually sufficient to look at the translations in a viewer like `IMOD <https://bio3d.colorado.edu/imod/>`_. The following assumes that you have IMOD installed and its command line tools linked.

.. code-block:: bash

    awk -F'\t' '
        BEGIN {OFS="\t"}
        NR==1 {next}
        {print 1, 1, $3, $2, $1}
    ' output.tsv > coordinates.tsv

    point2model -inp coordinates.tsv -ou coordinates.mod -ci 10

References
==========

.. [1] de Teresa-Trueba, I.; Goetz, S. K.; Mattausch, A.; Stojanovska, F.; Zimmerli, C. E.; Toro-Nahuelpan, M.; Cheng, D. W. C.; Tollervey, F.; Pape, C.; Beck, M.; Diz-Munoz, A.; Kreshuk, A.; Mahamid, J.; Zaugg, J. B. Convolutional networks for supervised mining of molecular patterns within cellular context. Nat. Methods 2023, 20, 284–294.
.. [2] Scheres, S.H.W. RELION: Implementation of a Bayesian approach to cryo-EM structure determination. J Struct Biol. 2012 Dec;180(3):519-30. doi: 10.1016/j.jsb.2012.09.006.
